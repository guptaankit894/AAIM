{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guptaankit894/AAIM/blob/main/google_colab_files/Copy_of_Dog_Cat_Classification_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33hbQCxBV2DB"
      },
      "source": [
        "Installing the suitable opencv version 3.4.2.17"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biqAtVeiys1H"
      },
      "source": [
        "#install opencv version 4.4.0.44 via this command\n",
        "!pip install opencv-contrib-python==3.4.2.17"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBBO2U1YA5Ep"
      },
      "source": [
        "# Download the Dataset\n",
        "\n",
        "https://www.microsoft.com/en-us/download/details.aspx?id=54765"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMxNaLJJVpED"
      },
      "source": [
        "import requests\n",
        "import zipfile\n",
        "\n",
        "url = 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "open('files.zip', 'wb').write(r.content) # download files\n",
        "\n",
        "path_to_zip_file = 'files.zip'\n",
        "directory_to_extract_to = 'cat_dog'\n",
        "\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAoP9lzdkpZ7"
      },
      "source": [
        "# Image classification\n",
        "Image classification framework consist of following steps:\n",
        "1. Loading appropriate python libraries.\n",
        "2. Reading images from the database and keep them in fixed dimensions.\n",
        "3. Flattening the images for using pixels as features.\n",
        "4. Splitting the data (features, labels) into training (80%) and test(20%) sets.\n",
        "5. Defining the Network architecture for initial model followed by compiling and model fitting.\n",
        "6. Testing the performance of the model using test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo-5MQK3bP39"
      },
      "source": [
        "#Loading Python Libraries\n",
        "This step will load all the required libraries for image preprocessing and working on neural networks.\n",
        "1. cv2(OpenCV)-Cv2 is a python library which allows image preprocessing like reading the images from the folders,converting them to gray-scale and resizing.It also allows extraction of features from the preprocessed images.\n",
        "2. Matplotlib-It is used for plotting the figures or images,e.g. for plotting the accuracy corresponding to the epochs,or preprocessed images.\n",
        "3. Numpy-It is used for numerical computations.\n",
        "4. Tensorflow-It is a machine learning library which provide the framework to work on the neural networks and its variants.\n",
        "5. Scikit Learn-is used for splitting the data into training and test sets.Although this library can be used for neural networks implementations as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgCRIy7IIOFr"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDkUAcrHdHiO"
      },
      "source": [
        "# Image Preprocessing\n",
        "It includes preparing the representation of images to feed to the classifier,which starts with reading images from the folder, converting them to gray scale,resizing and flattening.\n",
        "1. cv2.imread will be used for reading the images from the folder.\n",
        "2. cv2.cvtColor will tranform the color image to gray-scale using the reserved keyword cv2.COLOR_RGB2GRAY.\n",
        "3. cv2.resize is used to resize the images to keep a fixed dimensions for all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVEAeRHPPcMP"
      },
      "source": [
        "#DataSet Preparation\n",
        "dir=directory_to_extract_to+'/PetImages/'\n",
        "categories=[\"Cat\",\"Dog\"]\n",
        "data=[]\n",
        "for i in os.listdir(dir):\n",
        "    for j in os.listdir(os.path.join(dir,i)):\n",
        "        if j.endswith(\".jpg\"):\n",
        "            try:\n",
        "                img=cv2.imread(os.path.join(dir,i,j))\n",
        "                img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  #convert BGR2RGB\n",
        "                img=cv2.resize(img,(30,30))# image resizing\n",
        "                feat=img.flatten()   #flatten the image to single vector\n",
        "                feat=feat/255.0     #image normalization\n",
        "                data.append([feat,categories.index(i)])\n",
        "            except:\n",
        "                pass\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gBRIGViecAo"
      },
      "source": [
        "#Data Preprocessing\n",
        "This step will prepare the data to be fed to the classifier which includes data shuffling and converting the labels to one-hot encoding representations.Next step is to split the data into training and test data set.This tutorial splits the data in the 80:20 ratio.In other words,80% data will be kept for training and 20% data for testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo1tQ37APg0D"
      },
      "source": [
        "# Splitting the data into features and corresponding labels\n",
        "random.shuffle(data)   #shuffling of data\n",
        "features=[]\n",
        "labels=[]\n",
        "#Spliting the data into features and corresponding labels:variable \"features\" will have all the features whereas all the label information is present in \"labels\" variable.\n",
        "for i, j in data:\n",
        "  features.append(i)\n",
        "  labels.append(j)\n",
        "\n",
        "features=np.array(features)\n",
        "labels=np.array(labels)\n",
        "\n",
        "#Printing the size of the dataset.\n",
        "print(\"features size={},labels size={}\".format(features.shape,labels.shape))\n",
        "# One hot encoding\n",
        "target=tf.keras.utils.to_categorical(labels)\n",
        "print(target.shape)\n",
        "features=features.reshape((-1,features.shape[1]))\n",
        "\n",
        "X_train, X_test, Y_train, Y_test=train_test_split(features,target,test_size=0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpdmb2U5iiIe"
      },
      "source": [
        "# Model Training and Testing\n",
        "This step will define the architecture of the neural network for image classification,model compilation and fitting,performance evaluation.\n",
        "1. Defining the architecture deals with chossing the number of layers and units within each layer,weights initialization (glorot kernel initializer).\n",
        "2.Compiling the model includes defining the optimizer, accuarcy and loss functions.\n",
        "3. Fitting the model takes the training the data, number of iterations to train model, batch size and specifying the validation data size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo1Iz0owZufl"
      },
      "source": [
        "model=tf.keras.Sequential()\n",
        "model.add(Dense(256,activation='relu', kernel_initializer=glorot_uniform(seed=0),input_shape=(features.shape[1],)))\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "\n",
        "model.add(Dense(2,activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCuIvTfWZvzD"
      },
      "source": [
        "#Model compilation\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_niPNfUfZ8Y5",
        "outputId": "175d09f4-35c6-4fe2-df97-f946cbe6b989"
      },
      "source": [
        "# Model Fitting\n",
        "history= model.fit(X_train, Y_train, epochs=20, batch_size=10, validation_split=0.33, verbose=2)\n",
        "#Accuracy Plot\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.xlabel(\"No. of epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"train\",\"test\"])\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "#Loss Plot\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel(\"No. of epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"train\",\"test\"])\n",
        "plt.title(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1337/1337 - 7s - 5ms/step - accuracy: 0.5991 - loss: 0.6617 - val_accuracy: 0.5934 - val_loss: 0.6629\n",
            "Epoch 8/20\n",
            "1337/1337 - 4s - 3ms/step - accuracy: 0.6038 - loss: 0.6601 - val_accuracy: 0.6036 - val_loss: 0.6591\n",
            "Epoch 9/20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP8BFf2O-4mT"
      },
      "source": [
        "#Testing the performance of the model\n",
        "loss,accuracy=model.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co312RW85c4b"
      },
      "source": [
        "# Image Classification using Object of interest selection\n",
        "This activity helps in grasping few image processing steps for potentially better performance of the neural network model.This steps uses edge detection,dilation and masking to segment object of interest.We will see the effects of these concepts on the images and later will use all these steps to preprocess images of the dataset.This activity will use the same steps as the previous activity except image processing step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT14SxqPj71P"
      },
      "source": [
        "# Dog Example\n",
        "img=cv2.imread(directory_to_extract_to+'/PetImages/'+'/Dog/1022.jpg')\n",
        "img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "edges=cv2.Canny(img, 100, 160)  #Canny Edge Detection method\n",
        "kernel = np.ones((7,7),np.uint8)  #kernel\n",
        "edge1=cv2.dilate(edges,kernel,iterations=1) # dilation\n",
        "img3=cv2.bitwise_and(img,img,mask=edge1) # selecting object of interest\n",
        "plt.imshow(img3,cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omnLY8ZwnkhG"
      },
      "source": [
        "# Dog Example\n",
        "img=cv2.imread(directory_to_extract_to+'/PetImages/'+'/Cat/1022.jpg')\n",
        "img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "edges=cv2.Canny(img, 100, 160)  #Canny Edge Detection method\n",
        "kernel = np.ones((7,7),np.uint8)  #kernel\n",
        "edge1=cv2.dilate(edges,kernel,iterations=1) # dilation\n",
        "img3=cv2.bitwise_and(img,img,mask=edge1) # selecting object of interest\n",
        "plt.imshow(img3,cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-q5zh8QVMYR"
      },
      "source": [
        "# Image Processing function\n",
        "As learnt from the \"Introduction to Python\" let's create a function putting the image processing steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnsLD4o8p8q6"
      },
      "source": [
        "def img_process(img):\n",
        "    edges=cv2.Canny(img, 100, 160)  #Canny Edge Detection method\n",
        "    kernel = np.ones((7,7),np.uint8)  #kernel\n",
        "    edge1=cv2.dilate(edges,kernel,iterations=1)\n",
        "    img3=cv2.bitwise_and(img,img,mask=edge1)\n",
        "\n",
        "    return img3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-EpbLtPXbmF"
      },
      "source": [
        "# Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5d5QD0YWaRh"
      },
      "source": [
        "#DataSet Preparation\n",
        "dir=directory_to_extract_to+'/PetImages/'\n",
        "categories=[\"Cat\",\"Dog\"]\n",
        "data=[]\n",
        "for i in os.listdir(dir):\n",
        "    for j in os.listdir(os.path.join(dir,i)):\n",
        "        if j.endswith(\".jpg\"):\n",
        "            try:\n",
        "                img=cv2.imread(os.path.join(dir,i,j))\n",
        "                img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  #convert BGR2RGB\n",
        "                img=cv2.resize(img,(30,30))# image resizing\n",
        "                img=img_process(img) # image processing\n",
        "                feat=img.flatten()   #flatten the image to single vector\n",
        "                feat=feat/255.0     #image normalization\n",
        "                data.append([feat,categories.index(i)])\n",
        "            except:\n",
        "                pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl6qeZokXdPV"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R00dCYaGlFhd"
      },
      "source": [
        "# Splitting the data into features and corresponding labels\n",
        "random.shuffle(data)   #shuffling of data\n",
        "features=[]\n",
        "labels=[]\n",
        "#Spliting the data into features and corresponding labels:variable \"features\" will have all the features whereas all the label information is present in \"labels\" variable.\n",
        "for i, j in data:\n",
        "  features.append(i)\n",
        "  labels.append(j)\n",
        "\n",
        "features=np.array(features)\n",
        "labels=np.array(labels)\n",
        "\n",
        "#Printing the size of the dataset.\n",
        "print(\"features size={},labels size={}\".format(features.shape,labels.shape))\n",
        "# One hot encoding\n",
        "target=tf.keras.utils.to_categorical(labels)\n",
        "print(target.shape)\n",
        "features=features.reshape((-1,features.shape[1]))\n",
        "\n",
        "X_train, X_test, Y_train, Y_test=train_test_split(features,target,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai7PKsJsXQPs"
      },
      "source": [
        "# Model Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y21yHWsMKaE3"
      },
      "source": [
        "model=tf.keras.Sequential()\n",
        "model.add(Dense(256,activation='relu',kernel_initializer='glorot_uniform',input_shape=(features.shape[1],)))\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "\n",
        "model.add(Dense(2,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExDNfmvlXBNM"
      },
      "source": [
        "#Model compilation\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LmuWJjkXHiN"
      },
      "source": [
        "# Model Fitting\n",
        "history= model.fit(X_train, Y_train, epochs=20, batch_size=10, validation_split=0.33, verbose=2)\n",
        "#Accuracy Plot\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.xlabel(\"No. of epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"train\",\"test\"])\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "#Loss Plot\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel(\"No. of epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"train\",\"test\"])\n",
        "plt.title(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rILQo_UqXMye"
      },
      "source": [
        "#Testing the performance of the model\n",
        "loss,accuracy=model.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv58TgmwYIMC"
      },
      "source": [
        "# Image Classification using feature extraction Methods\n",
        "Features are used to feed the abstract representation to the neural networks. Constructing suitable feature sets for classification task greatly enhances the ability of the neural network model to discriminate between two or more classes.In this activity,we will be looking at two major feature extraction methods:Scale invariant feature transform (SIFT),Speed up robust feature(SURF)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhVZNGHJ5jTL"
      },
      "source": [
        "#DataSet Preparation\n",
        "directory_to_extract_to+'/PetImages/'\n",
        "categories=[\"Cat\",\"Dog\"]\n",
        "data=[]\n",
        "for i in os.listdir(dir):\n",
        "  for j in os.listdir(os.path.join(dir,i)):\n",
        "    if j.endswith(\".jpg\"):\n",
        "          try:\n",
        "              img=cv2.imread(os.path.join(dir,i,j))\n",
        "              img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)  #convert BGR2RGB\n",
        "              img=cv2.resize(img,(30,30))#image resize\n",
        "              sift = cv2.xfeatures2d.SIFT_create(4)\n",
        "              img=img_process(img)# image processing\n",
        "              keypoints,feat= sift.detectAndCompute(img, None)\n",
        "              feat=feat.flatten()\n",
        "              data.append([feat, categories.index(i)])\n",
        "          except:\n",
        "            pass\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRnn0Lz5eGZh"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CDr8qwjeFRh"
      },
      "source": [
        "# Splitting the data into features and corresponding labels\n",
        "random.shuffle(data)   #shuffling of data\n",
        "features=[]\n",
        "labels=[]\n",
        "#Spliting the data into features and corresponding labels:variable \"features\" will have all the features whereas all the label information is present in \"labels\" variable.\n",
        "for i, j in data:\n",
        "  features.append(i)\n",
        "  labels.append(j)\n",
        "\n",
        "# Storing the features in numpy array\n",
        "max_len = max([len(i) for i in features])\n",
        "sift_features=np.empty((0,max_len))\n",
        "for i in features:\n",
        "    i=np.array(i)\n",
        "    i= np.pad(i, (0, max_len-i.shape[0]), 'constant')    # padding the features with zeros for consistent dimensions\n",
        "    sift_features=np.vstack((sift_features,i))    #adding the features for each sample row by row\n",
        "\n",
        "\n",
        "#Feature normalization/Scaling\n",
        "sift_features=tf.keras.utils.normalize(sift_features, axis=-1, order=2)  #Feature scaling using L-2 norm\n",
        "\n",
        "# One hot encoding\n",
        "target=tf.keras.utils.to_categorical(labels)\n",
        "sift_features=sift_features.reshape((-1,sift_features.shape[1]))\n",
        "\n",
        "# Data Splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(sift_features, target, test_size=0.2)\n",
        "#Printing the size of the dataset.\n",
        "print(\"features size={},labels size={}\".format(sift_features.shape,target.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUFbuQgvbLl2"
      },
      "source": [
        "# Model Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riA4beSQYwQg"
      },
      "source": [
        "model=tf.keras.Sequential()\n",
        "model.add(Dense(256,activation='relu',kernel_initializer='glorot_uniform',input_shape=(sift_features.shape[1],)))\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "\n",
        "model.add(Dense(2,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1I_90prKcBn"
      },
      "source": [
        "#Model compilation\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Model Fitting\n",
        "history= model.fit(X_train, Y_train, epochs=20, batch_size=10,validation_split=0.33, verbose=2)\n",
        "#Accuracy Plot\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.xlabel(\"No. of epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"train\",\"test\"])\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "#Loss Plot\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel(\"No. of epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"train\",\"test\"])\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv9HBJHnPJ1H"
      },
      "source": [
        "loss,accuracy=model.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSRcBWz58AL7"
      },
      "source": [
        "# SURF Features detection and classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y543E8Ac8F1s"
      },
      "source": [
        "#DataSet Preparation\n",
        "dir=directory_to_extract_to+'/PetImages/'\n",
        "categories=[\"Cat\",\"Dog\"]\n",
        "data=[]\n",
        "for i in os.listdir(dir):\n",
        "  for j in os.listdir(os.path.join(dir,i)):\n",
        "    if j.endswith(\".jpg\"):\n",
        "          try:\n",
        "              img=cv2.imread(os.path.join(dir,i,j))\n",
        "              img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  #convert BGR2RGB\n",
        "              img=cv2.resize(img,(40,40))#resize\n",
        "              detector = cv2.xfeatures2d_SURF.create()\n",
        "              keypoints,feat = detector.detectAndCompute(img, None)\n",
        "              feat=feat.flatten()\n",
        "              data.append([feat, categories.index(i)])\n",
        "          except:\n",
        "            pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6eqg0BJbtSU"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yal6l2CRgxAg"
      },
      "source": [
        "# Splitting the data into features and corresponding labels\n",
        "random.shuffle(data)   #shuffling of data\n",
        "features=[]\n",
        "labels=[]\n",
        "#Spliting the data into features and corresponding labels:variable \"features\" will have all the features whereas all the label information is present in \"labels\" variable.\n",
        "for i, j in data:\n",
        "  features.append(i)\n",
        "  labels.append(j)\n",
        "\n",
        "# Storing the features in numpy array\n",
        "max_len = max([len(i) for i in features])\n",
        "surf_features=np.empty((0,max_len))\n",
        "for i in features:\n",
        "    i=np.array(i)\n",
        "    i= np.pad(i, (0, max_len-i.shape[0]), 'constant')    # padding the features with zeros for consistent dimensions\n",
        "    surf_features=np.vstack((surf_features,i))    #adding the features for each sample row by row\n",
        "\n",
        "\n",
        "#Feature normalization/Scaling\n",
        "surf_features=tf.keras.utils.normalize(surf_features, axis=-1, order=2)  #Feature scaling using L-2 norm\n",
        "\n",
        "# One hot encoding\n",
        "target=tf.keras.utils.to_categorical(labels)\n",
        "surf_features=surf_features.reshape((-1,surf_features.shape[1]))\n",
        "\n",
        "# Data Splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(surf_features, target, test_size=0.2)\n",
        "#Printing the size of the dataset.\n",
        "print(\"features size={},labels size={}\".format(surf_features.shape,target.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jcOD-7vhZSB"
      },
      "source": [
        "model=tf.keras.Sequential()\n",
        "model.add(Dense(256,activation='relu',kernel_initializer='glorot_uniform',input_shape=(surf_features.shape[1],)))\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "\n",
        "model.add(Dense(2,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lzROuSQhZSO"
      },
      "source": [
        "#Model compilation\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Model Fitting\n",
        "history= model.fit(X_train, Y_train, epochs=20, batch_size=10,validation_split=0.33, verbose=2)\n",
        "#Accuracy Plot\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.xlabel(\"No. of epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"train\",\"test\"])\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "#Loss Plot\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel(\"No. of epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"train\",\"test\"])\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1jFRiZDhZSP"
      },
      "source": [
        "loss,accuracy=model.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}